{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Feature_Engineering_I_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikKr5irSFISq"
      },
      "source": [
        "# Problem 1\n",
        "\n",
        "Your task is to increase the performance of the models that you implemented in the bank-of-words example. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "aQDZjEK-FISr"
      },
      "source": [
        "## Importing and Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:39:17.194286Z",
          "start_time": "2021-08-01T04:39:13.790357Z"
        },
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCsv4z4MFISs",
        "outputId": "d045444f-e074-45de-d5bc-b6a4cbce2b8e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import re\n",
        "import spacy\n",
        "from nltk.corpus import gutenberg\n",
        "import nltk\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# get gutenberg in here\n",
        "nltk.download('gutenberg')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:39:17.274265Z",
          "start_time": "2021-08-01T04:39:17.196633Z"
        },
        "hidden": true,
        "id": "hfdwZVYvFISs"
      },
      "source": [
        "# bring over the text cleaning function from the checkpoint notebook\n",
        "def text_cleaner(text):\n",
        "    text = re.sub(r'--', ' ', text)\n",
        "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
        "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "\n",
        "# load and clean the data as shown in the checkpoint notebook\n",
        "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
        "alice = gutenberg.raw('carroll-alice.txt')\n",
        "\n",
        "# get rid of the chapter headings\n",
        "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
        "alice = re.sub(r'CHAPTER .*', '', alice)\n",
        "\n",
        "# apply the text cleaning function\n",
        "persuasion = text_cleaner(persuasion)\n",
        "alice = text_cleaner(alice)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:39:52.864344Z",
          "start_time": "2021-08-01T04:39:17.276593Z"
        },
        "hidden": true,
        "hide_input": false,
        "id": "hK0qLbUGFISt"
      },
      "source": [
        "# parse them using spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "alice_doc = nlp(alice)\n",
        "persuasion_doc = nlp(persuasion)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:39:52.915031Z",
          "start_time": "2021-08-01T04:39:52.866945Z"
        },
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "NpYQ_V1TFISt",
        "outputId": "b1b0c719-6707-4be4-b089-f967b93c5436"
      },
      "source": [
        "# group the text data into sentences, so 1 doc = 1 sent\n",
        "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
        "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
        "\n",
        "# combine the sentences from both novels into one dataframe\n",
        "sentences_df = pd.DataFrame(alice_sents + persuasion_sents, columns=[\"text\", \"author\"])\n",
        "sentences_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Oh, dear, !)</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(I, shall, be, late, !, ')</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text   author\n",
              "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
              "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
              "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
              "3                                      (Oh, dear, !)  Carroll\n",
              "4                         (I, shall, be, late, !, ')  Carroll"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:39:53.368500Z",
          "start_time": "2021-08-01T04:39:52.916497Z"
        },
        "hidden": true,
        "id": "Bmb0VUa8FISt"
      },
      "source": [
        "# get rid of stop words, punctuation, and lemmatize\n",
        "for i, sentence in enumerate(sentences_df[\"text\"]):\n",
        "    sentences_df.loc[i, \"lemmas\"] = \" \".join([\n",
        "        token.lemma_ for token in sentence\n",
        "        if not token.is_punct and not token.is_stop\n",
        "    ])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:39:53.379979Z",
          "start_time": "2021-08-01T04:39:53.370210Z"
        },
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "iOHa1XiDFISu",
        "outputId": "47d64b5d-506e-4369-ef80-b2384c61c909"
      },
      "source": [
        "sentences_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "      <th>lemmas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>remarkable Alice think way hear Rabbit oh dear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Oh, dear, !)</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>oh dear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(I, shall, be, late, !, ')</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>shall late</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                             lemmas\n",
              "0  (Alice, was, beginning, to, get, very, tired, ...  ...  Alice begin tired sit sister bank have twice p...\n",
              "1  (So, she, was, considering, in, her, own, mind...  ...  consider mind hot day feel sleepy stupid pleas...\n",
              "2  (There, was, nothing, so, VERY, remarkable, in...  ...     remarkable Alice think way hear Rabbit oh dear\n",
              "3                                      (Oh, dear, !)  ...                                            oh dear\n",
              "4                         (I, shall, be, late, !, ')  ...                                         shall late\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "UdB9nhffFISu"
      },
      "source": [
        "## Initial Model\n",
        "\n",
        "|  | LR Score | RF Score | GB Score |\n",
        "|---|---|---|---|\n",
        "| Training Set | 0.945 | 0.981 | 0.860 |\n",
        "| Test Set | 0.894 | 0.884 | 0.847 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:39:53.821901Z",
          "start_time": "2021-08-01T04:39:53.381634Z"
        },
        "hidden": true,
        "id": "x-1IvKtUFISu"
      },
      "source": [
        "# prepare the initial model dataframe from the checkpoint notebook\n",
        "# using bag of words\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(analyzer='word')\n",
        "X = vectorizer.fit_transform(sentences_df['lemmas'])\n",
        "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
        "sentences_df = pd.concat([bow_df, sentences_df[[\"lemmas\", \"author\", \"text\"]]], axis=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:40:59.852831Z",
          "start_time": "2021-08-01T04:39:53.825827Z"
        },
        "hidden": true,
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roYzzyDKFISv",
        "outputId": "5874e713-dcb1-4675-9f03-ae8a225d12b8"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Y = sentences_df['author'] # target variable, who is the author?\n",
        "X = np.array(sentences_df.drop(['text', 'author', 'lemmas'], 1)) # only want the b-o-w\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
        "\n",
        "# Models\n",
        "lr = LogisticRegression()\n",
        "rfc = RandomForestClassifier()\n",
        "gbc = GradientBoostingClassifier()\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "rfc.fit(X_train, y_train)\n",
        "gbc.fit(X_train, y_train)\n",
        "\n",
        "print(\"----------------------Logistic Regression Scores----------------------\")\n",
        "print('Training set score:', lr.score(X_train, y_train))\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Random Forest Scores----------------------\")\n",
        "print('Training set score:', rfc.score(X_train, y_train))\n",
        "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
        "print('Training set score:', gbc.score(X_train, y_train))\n",
        "print('\\nTest set score:', gbc.score(X_test, y_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------Logistic Regression Scores----------------------\n",
            "Training set score: 0.9261687571265679\n",
            "\n",
            "Test set score: 0.8641025641025641\n",
            "----------------------Random Forest Scores----------------------\n",
            "Training set score: 0.9723489167616876\n",
            "\n",
            "Test set score: 0.8264957264957264\n",
            "----------------------Gradient Boosting Scores----------------------\n",
            "Training set score: 0.8275370581527937\n",
            "\n",
            "Test set score: 0.8128205128205128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_style": "split",
        "heading_collapsed": true,
        "id": "YK8SpX0QFISv"
      },
      "source": [
        "## Using Parts of Speech\n",
        "\n",
        "Performs worse than initial model.\n",
        "\n",
        "**Model with \"1-gram\" parts of speech**\n",
        "\n",
        "|  | LR Score | RF Score | GB Score |\n",
        "|---|---|---|---|\n",
        "| Training Set | 0.693 | 0.833 | 0.746 |\n",
        "| Test Set | 0.695 | 0.704 | 0.727 |\n",
        "\n",
        "**Model with \"2-grams\" parts of speech**\n",
        "\n",
        "|  | LR Score | RF Score | GB Score |\n",
        "|---|---|---|---|\n",
        "| Training Set | 0.738 | 0.882 | 0.764 |\n",
        "| Test Set | 0.727 | 0.716 | 0.733 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_style": "split",
        "hidden": true,
        "id": "M5h29XkfFISv"
      },
      "source": [
        "For the purposes of this notebook, I want to explore the addition of a feature that counts the instances of various parts of speech.\n",
        "\n",
        "In the following two cells, I create a column with the parts of speech used in each sentence. Then, I apply the bag-of-words method to this column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:41:01.309321Z",
          "start_time": "2021-08-01T04:40:59.855512Z"
        },
        "cell_style": "split",
        "hidden": true,
        "id": "wiVZmzr8FISw"
      },
      "source": [
        "# get the pos\n",
        "for i, sentence in enumerate(sentences_df[\"text\"]):\n",
        "    sentences_df.loc[i, \"pos\"] = \" \".join([\n",
        "        token.pos_ for token in sentence\n",
        "        if not token.is_punct and not token.is_stop\n",
        "    ])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:41:01.419984Z",
          "start_time": "2021-08-01T04:41:01.311811Z"
        },
        "cell_style": "center",
        "hidden": true,
        "id": "ry4Z95LDFISx"
      },
      "source": [
        "# apply bag-of-words method to the 'pos' column\n",
        "vectorizer = CountVectorizer(analyzer='word')\n",
        "X = vectorizer.fit_transform(sentences_df['pos'])\n",
        "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
        "sentences_df = pd.concat([bow_df, sentences_df[[\"lemmas\", \"author\", \"text\", \"pos\"]]], axis=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:41:01.446261Z",
          "start_time": "2021-08-01T04:41:01.421747Z"
        },
        "hidden": true,
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "6229SH8dFISx",
        "outputId": "ce5c0e50-b629-4005-c582-f2410629a627"
      },
      "source": [
        "# check it out\n",
        "sentences_df"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>adj</th>\n",
              "      <th>adp</th>\n",
              "      <th>adv</th>\n",
              "      <th>det</th>\n",
              "      <th>intj</th>\n",
              "      <th>noun</th>\n",
              "      <th>num</th>\n",
              "      <th>part</th>\n",
              "      <th>pron</th>\n",
              "      <th>propn</th>\n",
              "      <th>punct</th>\n",
              "      <th>sconj</th>\n",
              "      <th>verb</th>\n",
              "      <th>lemmas</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
              "      <td>PROPN VERB ADJ VERB NOUN NOUN VERB ADV VERB NO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
              "      <td>VERB NOUN ADJ NOUN VERB ADJ ADJ NOUN VERB NOUN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>remarkable Alice think way hear Rabbit oh dear</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
              "      <td>ADJ PROPN VERB NOUN VERB PROPN INTJ INTJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>oh dear</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>(Oh, dear, !)</td>\n",
              "      <td>INTJ INTJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>shall late</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>(I, shall, be, late, !, ')</td>\n",
              "      <td>VERB ADJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5843</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>spring felicity glow spirit friend Anne warmth...</td>\n",
              "      <td>Austen</td>\n",
              "      <td>(Her, spring, of, felicity, was, in, the, glow...</td>\n",
              "      <td>NOUN NOUN NOUN NOUN NOUN PROPN NOUN NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5844</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Anne tenderness worth Captain Wentworth affection</td>\n",
              "      <td>Austen</td>\n",
              "      <td>(Anne, was, tenderness, itself, ,, and, she, h...</td>\n",
              "      <td>PROPN ADP NOUN PROPN PROPN NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5845</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>profession friend wish tenderness dread future...</td>\n",
              "      <td>Austen</td>\n",
              "      <td>(His, profession, was, all, that, could, ever,...</td>\n",
              "      <td>NOUN NOUN VERB VERB NOUN ADJ NOUN VERB NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5846</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>glory sailor wife pay tax quick alarm belong p...</td>\n",
              "      <td>Austen</td>\n",
              "      <td>(She, gloried, in, being, a, sailor, 's, wife,...</td>\n",
              "      <td>VERB NOUN NOUN VERB NOUN ADJ NOUN VERB NOUN AD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5847</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Finis</td>\n",
              "      <td>Austen</td>\n",
              "      <td>(Finis)</td>\n",
              "      <td>PROPN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5848 rows Ã— 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      adj  ...                                                pos\n",
              "0       1  ...  PROPN VERB ADJ VERB NOUN NOUN VERB ADV VERB NO...\n",
              "1       5  ...  VERB NOUN ADJ NOUN VERB ADJ ADJ NOUN VERB NOUN...\n",
              "2       1  ...           ADJ PROPN VERB NOUN VERB PROPN INTJ INTJ\n",
              "3       0  ...                                          INTJ INTJ\n",
              "4       1  ...                                           VERB ADJ\n",
              "...   ...  ...                                                ...\n",
              "5843    0  ...           NOUN NOUN NOUN NOUN NOUN PROPN NOUN NOUN\n",
              "5844    0  ...                    PROPN ADP NOUN PROPN PROPN NOUN\n",
              "5845    1  ...        NOUN NOUN VERB VERB NOUN ADJ NOUN VERB NOUN\n",
              "5846    5  ...  VERB NOUN NOUN VERB NOUN ADJ NOUN VERB NOUN AD...\n",
              "5847    0  ...                                              PROPN\n",
              "\n",
              "[5848 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:41:02.085756Z",
          "start_time": "2021-08-01T04:41:01.448264Z"
        },
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awgZQR-KFISx",
        "outputId": "7e5c755c-c6d4-4f49-d808-74cbfebbc80c"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Y = sentences_df['author'] # target variable, who is the author?\n",
        "X = np.array(sentences_df.drop(['text', 'author', 'lemmas', 'pos'], 1)) # only want the b-o-w\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
        "\n",
        "# Models\n",
        "lr = LogisticRegression()\n",
        "rfc = RandomForestClassifier()\n",
        "gbc = GradientBoostingClassifier()\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "rfc.fit(X_train, y_train)\n",
        "gbc.fit(X_train, y_train)\n",
        "\n",
        "print(\"----------------------Logistic Regression Scores----------------------\")\n",
        "print('Training set score:', lr.score(X_train, y_train))\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Random Forest Scores----------------------\")\n",
        "print('Training set score:', rfc.score(X_train, y_train))\n",
        "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
        "print('Training set score:', gbc.score(X_train, y_train))\n",
        "print('\\nTest set score:', gbc.score(X_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------Logistic Regression Scores----------------------\n",
            "Training set score: 0.6468072976054732\n",
            "\n",
            "Test set score: 0.6482905982905983\n",
            "----------------------Random Forest Scores----------------------\n",
            "Training set score: 0.7916191562143672\n",
            "\n",
            "Test set score: 0.6816239316239316\n",
            "----------------------Gradient Boosting Scores----------------------\n",
            "Training set score: 0.7183580387685291\n",
            "\n",
            "Test set score: 0.6897435897435897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:41:02.150348Z",
          "start_time": "2021-08-01T04:41:02.087436Z"
        },
        "hidden": true,
        "id": "JzKEamAbFISy"
      },
      "source": [
        "# what if we tried \"2-grams\" with the pos?\n",
        "vectorizer = CountVectorizer(analyzer='word', ngram_range=(2,2))\n",
        "X = vectorizer.fit_transform(sentences_df['pos'])\n",
        "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
        "sentences_df = pd.concat([bow_df, sentences_df[[\"lemmas\", \"author\", \"text\", \"pos\"]]], axis=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:41:03.359358Z",
          "start_time": "2021-08-01T04:41:02.152084Z"
        },
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90VAV_T5FISy",
        "outputId": "2f852d5a-2dad-4192-b350-b0554ca83635"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Y = sentences_df['author'] # target variable, who is the author?\n",
        "X = np.array(sentences_df.drop(['text', 'author', 'lemmas', 'pos'], 1)) # only want the b-o-w\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
        "\n",
        "# Models\n",
        "lr = LogisticRegression()\n",
        "rfc = RandomForestClassifier()\n",
        "gbc = GradientBoostingClassifier()\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "rfc.fit(X_train, y_train)\n",
        "gbc.fit(X_train, y_train)\n",
        "\n",
        "print(\"----------------------Logistic Regression Scores----------------------\")\n",
        "print('Training set score:', lr.score(X_train, y_train))\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Random Forest Scores----------------------\")\n",
        "print('Training set score:', rfc.score(X_train, y_train))\n",
        "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
        "print('Training set score:', gbc.score(X_train, y_train))\n",
        "print('\\nTest set score:', gbc.score(X_test, y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------Logistic Regression Scores----------------------\n",
            "Training set score: 0.6998289623717218\n",
            "\n",
            "Test set score: 0.6974358974358974\n",
            "----------------------Random Forest Scores----------------------\n",
            "Training set score: 0.8349486887115165\n",
            "\n",
            "Test set score: 0.6568376068376068\n",
            "----------------------Gradient Boosting Scores----------------------\n",
            "Training set score: 0.7152223489167617\n",
            "\n",
            "Test set score: 0.7029914529914529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_style": "center",
        "id": "DtIBKwACFISz"
      },
      "source": [
        "# Problem 2\n",
        "\n",
        "In the 2-gram example above, you only used 2-gram as your features. This time, use both 1-gram and 2-gram features together as your feature set. Run the same models as in the example and compare the results.\n",
        "\n",
        "Looks like the model with both 1 and 2-grams performs best.\n",
        "\n",
        "**1-gram model**\n",
        "\n",
        "|  | LR Score | RF Score | GB Score |\n",
        "|---|---|---|---|\n",
        "| Training Set | 0.935 | 0.980 | 0.851 |\n",
        "| Test Set | 0.876 | 0.854 | 0.836 |\n",
        "\n",
        "**2-gram model**\n",
        "\n",
        "|  | LR Score | RF Score | GB Score |\n",
        "|---|---|---|---|\n",
        "| Training Set | 0.917 | 0.953 | 0.766 |\n",
        "| Test Set | 0.783 | 0.798 | 0.762 |\n",
        "\n",
        "**Both 1 and 2-gram model**\n",
        "\n",
        "|  | LR Score | RF Score | GB Score |\n",
        "|---|---|---|---|\n",
        "| Training Set | 0.944 | 0.972 | 0.829 |\n",
        "| Test Set | 0.866 | 0.830 | 0.815 |\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-08-01T04:56:17.670513Z",
          "start_time": "2021-08-01T04:56:12.955122Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "pZ9d-Cm8FIS0",
        "outputId": "fcccb534-690b-4565-f8de-8de073ab0a16"
      },
      "source": [
        "# we'll use both 1 and 2-grams\n",
        "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,2)) # here\n",
        "X = vectorizer.fit_transform(sentences_df[\"lemmas\"])\n",
        "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
        "sentences_df = pd.concat([bow_df, sentences_df[[\"author\"]]], axis=1)\n",
        "sentences_df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1st</th>\n",
              "      <th>29th</th>\n",
              "      <th>29th september</th>\n",
              "      <th>abbreviation</th>\n",
              "      <th>abbreviation living</th>\n",
              "      <th>abdication</th>\n",
              "      <th>abdication neighbour</th>\n",
              "      <th>abide</th>\n",
              "      <th>abide consequence</th>\n",
              "      <th>abide figure</th>\n",
              "      <th>ability</th>\n",
              "      <th>ability affection</th>\n",
              "      <th>ability awkwardness</th>\n",
              "      <th>ability difficulty</th>\n",
              "      <th>able</th>\n",
              "      <th>able attempt</th>\n",
              "      <th>able avail</th>\n",
              "      <th>able avoid</th>\n",
              "      <th>able bear</th>\n",
              "      <th>able convince</th>\n",
              "      <th>able devise</th>\n",
              "      <th>able eat</th>\n",
              "      <th>able far</th>\n",
              "      <th>able feign</th>\n",
              "      <th>able join</th>\n",
              "      <th>able judge</th>\n",
              "      <th>able leave</th>\n",
              "      <th>able letter</th>\n",
              "      <th>able live</th>\n",
              "      <th>able marry</th>\n",
              "      <th>able persuade</th>\n",
              "      <th>able regard</th>\n",
              "      <th>able remain</th>\n",
              "      <th>able return</th>\n",
              "      <th>able ring</th>\n",
              "      <th>able rise</th>\n",
              "      <th>able set</th>\n",
              "      <th>able shew</th>\n",
              "      <th>able speak</th>\n",
              "      <th>able tell</th>\n",
              "      <th>...</th>\n",
              "      <th>young woman</th>\n",
              "      <th>young young</th>\n",
              "      <th>younker</th>\n",
              "      <th>youth</th>\n",
              "      <th>youth beauty</th>\n",
              "      <th>youth bloom</th>\n",
              "      <th>youth early</th>\n",
              "      <th>youth father</th>\n",
              "      <th>youth fine</th>\n",
              "      <th>youth hardly</th>\n",
              "      <th>youth hope</th>\n",
              "      <th>youth jaw</th>\n",
              "      <th>youth kill</th>\n",
              "      <th>youth learn</th>\n",
              "      <th>youth like</th>\n",
              "      <th>youth mention</th>\n",
              "      <th>youth possibly</th>\n",
              "      <th>youth restore</th>\n",
              "      <th>youth say</th>\n",
              "      <th>youth spring</th>\n",
              "      <th>youth value</th>\n",
              "      <th>youth vigour</th>\n",
              "      <th>youthful</th>\n",
              "      <th>youthful infatuation</th>\n",
              "      <th>zeal</th>\n",
              "      <th>zeal business</th>\n",
              "      <th>zeal common</th>\n",
              "      <th>zeal dwell</th>\n",
              "      <th>zeal sport</th>\n",
              "      <th>zeal think</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zealand australia</th>\n",
              "      <th>zealous</th>\n",
              "      <th>zealous officer</th>\n",
              "      <th>zealous subject</th>\n",
              "      <th>zealously</th>\n",
              "      <th>zealously discharge</th>\n",
              "      <th>zigzag</th>\n",
              "      <th>zigzag go</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 35312 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1st  29th  29th september  ...  zigzag  zigzag go   author\n",
              "0    0     0               0  ...       0          0  Carroll\n",
              "1    0     0               0  ...       0          0  Carroll\n",
              "2    0     0               0  ...       0          0  Carroll\n",
              "3    0     0               0  ...       0          0  Carroll\n",
              "4    0     0               0  ...       0          0  Carroll\n",
              "\n",
              "[5 rows x 35312 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2021-08-01T04:57:41.621Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66bEq9N6FIS0",
        "outputId": "c10512bf-8e67-4e79-dc4a-85ca82b3881b"
      },
      "source": [
        "Y = sentences_df['author']\n",
        "X = np.array(sentences_df.drop(['author'], 1))\n",
        "\n",
        "# We split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
        "\n",
        "# Models\n",
        "lr = LogisticRegression()\n",
        "rfc = RandomForestClassifier()\n",
        "gbc = GradientBoostingClassifier()\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "rfc.fit(X_train, y_train)\n",
        "gbc.fit(X_train, y_train)\n",
        "\n",
        "print(\"----------------------Logistic Regression Scores----------------------\")\n",
        "print('Training set score:', lr.score(X_train, y_train))\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Random Forest Scores----------------------\")\n",
        "print('Training set score:', rfc.score(X_train, y_train))\n",
        "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
        "print('Training set score:', gbc.score(X_train, y_train))\n",
        "print('\\nTest set score:', gbc.score(X_test, y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------Logistic Regression Scores----------------------\n",
            "Training set score: 0.9444127708095781\n",
            "\n",
            "Test set score: 0.8662393162393163\n",
            "----------------------Random Forest Scores----------------------\n",
            "Training set score: 0.9723489167616876\n",
            "\n",
            "Test set score: 0.82991452991453\n",
            "----------------------Gradient Boosting Scores----------------------\n",
            "Training set score: 0.8292474344355758\n",
            "\n",
            "Test set score: 0.8153846153846154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-t_1POmFIS1"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}